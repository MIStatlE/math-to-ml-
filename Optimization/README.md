## 最优化理论 📊

> **定位**  
> 最优化理论研究在给定约束下，使目标函数达到极值（通常为最小值）的原理、算法与性能界限，是 **机器学习与数据科学的“计算引擎”**。

| 维度 | 说明 |
|------|------|
| **核心任务** | 在连续/离散决策空间中，找到或逼近目标函数最优值；分析算法收敛速率与复杂度下界。 |
| **关键要素** | 凸性、光滑性、强凸／弱凸、条件数、自适应步长、随机梯度、对偶性、松弛与罚函数。 |
| **与机器学习的接口** | - **模型训练**：经验风险最小化 (ERM)、正则化、深度学习的梯度下降变体。<br> - **泛化与统计**：优化误差 + 估计误差 的统一分析框架。<br> - **推理与控制**：强化学习中的策略优化、Bayesian inference 中的对数后验最大化。 |
| **想解决的基本问题** | 1. **表示**：如何将实际学习/决策问题表述为可解的优化模型？<br>2. **算法**：对不同结构（凸/非凸、稀疏、低秩）的问题设计高效方法。<br>3. **上界**：算法收敛速率能做到多快？精度 ε 需要多少迭代 / 样本？<br>4. **下界**：是否存在信息论或计算复杂度的不可逾越界限？<br>5. **适应性**：算法能否无需先验地自适应光滑性、噪声水平或分布漂移？ |

---

## 📚 教材简评

| 教材 | 特色 | 适合人群 | 略有不足 |
|------|------|----------|----------|
| **《First-Order Methods in Optimization》<br>Amir Beck, 2017 (MOS-SIAM)** | 系统梳理一阶方法：梯度下降、加速、镜像、坐标下降、分布式优化；重视 **收敛率证明** 与“黑盒” oracle 模型下界。 | 已学过凸分析、线性代数，希望深入算法与复杂度的研究生。 | 理论符号密集。 |
| **《最优化（第 4 版）》<br>文再文** | 国内常用教材之一；覆盖线性规划、对偶理论、KKT 条件、整数规划及启发式。配大量例题与习题，贴合考研、工科课程。 | 本科高年级、初学者。 | 偏重应用与计算步骤，理论深度（如复杂度、收敛率）有限，更侧重经典优化的内容。 |
| **《最优化》<br>陈宝林** | 以 **凸优化 + 非线性规划** 为主线，单纯性法、牛顿法等经典算法，内容更传统，更偏应用。 | 需要从零系统学习凸/非线性优化并动手实践的本科生 / 研究生。 | 细节推导有时较快，读者需具备一定高数、线代与几何基础。 |

---

## 🌐 推荐网课资源

1. **[中国大学MOOC《最优化理论》 - 陈宝林](https://www.icourse163.org/course/ZJU-1002522006)**  
   - 本课程由浙江大学陈宝林教授讲解，内容深入浅出，涵盖了最优化理论的基本概念、算法与应用，适合本科生和研究生入门，内容相对没有很前沿。

2. **[Coursera - Convex Optimization by Boyd & Vandenberghe](https://www.youtube.com/watch?v=kV1ru-Inzl4)**  
   - 斯坦福大学的经典课程，由 Boyd 教授主讲，覆盖凸优化的核心理论与应用，适合工科学生，是学习最优化理论的权威资源。

---

## 🧑‍🏫 学习路径建议

> - **初学者**：可以从中文网课 *《最优化理论》* 入手，结合经典教材 *文再文*，打好基础。  
> - **进阶学习**：推荐学习 *Boyd & Vandenberghe* 的英文教材和 Coursera 上的优化相关课程，掌握凸优化的深层次理论与应用。  
> - **学术研究**：结合 *Amir Beck* 的教材进行一阶方法的深入学习，拓展到更复杂的非凸优化与机器学习中的优化问题。  
