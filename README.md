# 关于我

大家好，我是 **MIStatlE** 🎓  
目前研究生就读于 **复旦大学**，研究方向聚焦 **机器学习理论**。  

在 **小红书** 等平台，我均使用同名账号 **@MIStatlE**。  
我将持续整理学习过程中遇到的高价值书籍、笔记与优质的课程，构建一座**小而精的资源库**，希望为你的学习之旅提供助力与灵感。🚀

水平有限，如有不尽人意之处欢迎在社交平台反馈！

# 关于为什么想做这样一件事
在信息爆炸的时代，新兴学科层出不穷，书籍与资料更是琳琅满目。以 Online Learning 为例，它可以视作最优化理论的延伸领域。然而，许多教材为了照顾读者的基础，往往会加入大量背景内容，如集中不等式、概率测度等，这在阅读时无形中增加了时间成本。同时，不同作者在符号体系、叙述方式上的差异，也使得读者需要花费额外精力去适应和理解其逻辑结构。
正因如此，我常在想：如果能将这些学科系统地梳理起来，以统一的符号体系与叙述思路重新呈现，是否能让学习过程更高效、更连贯？这不仅能节省查找与切换思路的时间，也许还能为后来者铺平探索之路。这正是我开始着手整理相关笔记与文章的初衷。

# 📚 机器学习理论导论

机器学习理论（Machine Learning Theory, **MLT**）致力于回答这样一些**根本问题**：

| 典型问题 | 示例 |
|-----------|-------|
| **可学性** | 什么样的问题可以通过有限数据被算法**可靠学习**？（PAC 学习、VC 维） |
| **样本复杂度** | 要达到给定误差，需要 **多少样本**？（一致收敛、Rademacher 复杂度） |
| **算法复杂度** | 存在 **高效**（多项式时间）同时又统计最优的算法吗？（信息论下界 vs. 算法上界） |
| **泛化能力** | 为什么深度网络在过参数化下仍能 **泛化**？（隐式正则、平坦最小化） |
| **探索与利用** | 在交互式环境中，如何权衡 **试探**与 **收益**？（Multi-Armed Bandit、强化学习后悔界） |

> **一句话**：MLT 关心「什么能学、学多少、多久学到、用什么学」——并用**数学证明**给出答案。

---

## 🗺️ 学习路径总览

| 阶段 | 建议课程 | 目标与能力 |
|------|----------|------------|
| **Ⅰ. 数学基础** | 高等数学 + 线性代数 + 概率统计 → 现代概率论 ➕ 优化理论 | 搭建分析与证明工具箱 |
| **Ⅱ. 核心理论** | 统计学习理论 → 高维概率 → 凸优化与对偶 → 泛化与复杂度 | 掌握 PAC/VC、Rademacher、信息论等关键框架 |
| **Ⅲ. 高级专题** | 强化学习理论 → 在线/Bandit 学习 → 深度学习理论 | 站在前沿阅读顶会 / 论文，理解开放问题 |
| **Ⅳ. 研究实践** | 研读 COLT / NeurIPS / ICML 理论论文 | 能独立追踪 & 评价最新进展 |

---

## 🔗 先修要求（Prerequisites）
本资源库适合已经学过高等数学、线性代数、概率论与数理统计的本科生、研究生。若为低年级本科生，推荐下列资料

| 课程 | Books | Notes / Slides | MOOCs / 视频课 | 先修课 | 在 MLT 中的作用 |
|------|-------|----------------|---------------|--------|-----------------|
| **线性代数** | 《线性代数（第七版）》— 同济大学；《线性代数及其应用（原书第5版）》— Lay；*Matrix Analysis* — Horn & Johnson | 清华大学水木学堂线代笔记；MIT 18.06 Lecture Notes | 中国大学 MOOC《线性代数·陈纪修》；Bilibili「3Blue1Brown 线代本质」 | - | 向量空间、特征分解、SVD 是泛化与优化理论的基石 |
| **概率论与数理统计** | 《概率论与数理统计（第五版）》— 茆诗松；《A First Course in Probability》— Ross；*Statistical Inference* — Casella & Berger | 北大吴凌云课程讲义；CMU 36-705 Lecture Notes | 中国大学 MOOC《概率论与数理统计》；Harvard *Stat 110*（YouTube） | 高等数学 | 随机变量与极限定理直觉，为泛化误差分析和上下界推导奠基 |
| **高等数学 / 微积分** | 《高等数学（第七版）》— 同济大学；《微积分（第8版）》— James Stewart | 浙江大学陈睿《高数真题与解析》课件 | 中国大学 MOOC《高等数学》；MIT OCW *Single Variable Calculus* | - | 极限、微分与积分工具是解析损失函数、推导收敛率的基础 |



---

## 🛠 该资源库的定位

| 目标 | 说明 |
|------|------|
| **体系化地图** | 按阶段梳理必备知识块，帮助快速定位盲区 |
| **课程索引** | 对每门课给出作用说明和先修要求，便于规划学习顺序 |
| **轻量化入口** | 提供大纲与指北，请按照需求选择适合自己的资料 |



> ✨ **愿景**：搭建面向研究者的机器学习理论“索引站”，让每位学习者都能站在清晰的坐标系上启程。



> 每个子目录下包含  
> • 📚 **books/** – 官方 PDF / 合法电子稿  
> • 📝 **notes/** – PDF 笔记（会不定期持续更新，发过的也可能会回炉重造哦）  
> • 🔗 **links.md** – 高质量外部资源索引  
> • 📄 **README.md** – 学科定位、核心问题与学习路线指引  

### 中文教材 vs. 英文教材（数学类课程）
谈谈关于我个人使用英文教材与中文教材的体会

| 维度 | 中文教材特点 | 英文教材特点 | 适合人群 |
|------|-------------|-------------|----------|
| **体系结构** | 叙述更简洁、突出核心内容，相对关于insight的部分会含蓄晦涩一点 | 例题更多，会阐述更多motivation、intuition的内容 | 英文更适合自学；中文更适合复习 |
| **语言门槛** | 母语阅读压力低，吸收快；术语与国际文献偶有差异 | 术语与论文一致，训练学术英语 | 英语基础薄弱 → 中文起步；计划留学/阅读原版论文 → 早接触英文 |
| **例题与习题** | 题量大、覆盖应试风格，侧重计算套路 | 题目梯度更多，每一步推导都可以当成独立的题目，重证明与思辨； | 需要刷题巩固 → 中文；想锻炼思维深度 → 英文 |
| **更新速度** | 教材审定周期长，经典稳定；新兴方向稀缺 | 迭代快，常纳入最新研究案例 | 基础课差异小；前沿课程（MLT、凸优化）→ 首选英文 |

--- 

> 📝 **Notes 将提供中 / 英双语版本**  
> * `notes/zh/` — **中文版笔记**：注重直观讲解、计算技巧与常见考点  
> * `notes/en/` — **English Notes**：保持正式术语，完整给出定义-定理-证明链  
>   
> 两个版本内容彼此对应但更新节奏可能不同步；英文版本更新更快。






